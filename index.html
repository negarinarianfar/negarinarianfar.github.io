<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Negarin Arianfar</title>
<link rel="stylesheet" href="assets/style.css">

</head>

<body>
  <div class="container">

    <nav>
      <a href="#about">About</a>
      <a href="#vision">Research Vision</a>
      <a href="#projects">Projects</a>
      <a href="#books">Books</a>
      <a href="#cv">CV</a>
      <a href="#contact">Contact</a>
    </nav>

    <header class="hero">
      <span class="kicker"><span class="dot"></span> Prospective PhD Applicant • Reinforcement Learning</span>
      <h1>Negar Arianfar</h1>
      <img class="profile-pic" src="/assets/img/Profile.jpg" alt="Negar Arianfar" />
      <p class="subtitle">
        Applied Reinforcement Learning • Decision Systems • From Theory to Implementation
      </p>
      <p class="subtitle">
        I work on applied reinforcement learning and sequential decision-making
        bridging theory to reproducible implementations (PyTorch, custom environments, evaluation).
      </p>

      <div class="cta">
        <a class="btn primary" href="https://github.com/negarinarianfar" target="_blank">GitHub</a>
        <a class="btn" href="#projects">View Research Projects</a>
        <a class="btn" href="mailto:negarinarianfar@gmail.com">Email</a>
      </div>

      <div class="grid">
        <div class="card">
          <h3>Research Interests</h3>
          <p class="muted">
            Reinforcement Learning • Decision-Making Systems • Reward Design • Safe & Robust Learning • Multi-Agent / Distributed Optimization
          </p>
          <div class="tags">
            <span class="tag">RL</span>
            <span class="tag">DQN</span>
            <span class="tag">MDP Modeling</span>
            <span class="tag">Reward Shaping</span>
            <span class="tag">Evaluation</span>
          </div>
        </div>

        <div class="card">
          <h3>Currently Working On</h3>
          <p class="muted">
            Rewriting my earlier work in energy-aware optimization into an RL formulation and building an implementable research prototype.
          </p>
          <div class="tags">
            <span class="tag">Working Paper</span>
            <span class="tag">RL for Optimization</span>
            <span class="tag">From Theory → Implementation</span>
          </div>
        </div>
      </div>
    </header>

    <section class="section" id="about">
      <h2>About</h2>
      <p class="muted">
        I am an applied ML researcher focused on building reinforcement learning systems that can be tested,
        measured, and extended. I enjoy designing environments, implementing agents, and running structured evaluations
        to answer research questions with reproducible code.
      </p>
      <p class="muted">
        M.Sc. in Business Management
  International Marketing & Sales  
  Hochschule der Wirtschaft für Management (HDWM), Germany (2023–2025)<br>
M.Sc. in Software Engineering
  University of Najaf Abad Azad, Iran (2014–2018)<br>
B.Sc. in Hardware Engineering
  University of Najaf Abad Azad, Iran (2008–2014)
      </p>
    </section>

    <section class="section" id="vision">
  <h2>Research Vision</h2>
  <p class="muted">
    My research focuses on designing reinforcement learning systems that move beyond theoretical formulation toward robust, reproducible implementations.
    I am particularly interested in how environment modeling, reward design, and stability mechanisms influence long-term decision performance.
  </p>
  <p class="muted">
    I aim to develop learning-based optimization frameworks for distributed and strategic decision-making problems, 
    with an emphasis on reliability, evaluation methodology, and practical scalability.
  </p>
<div class="section" id="research-questions">
<h2>Research Questions</h2>

<div class="research-questions">
<ul>
<li>
How does reward design influence stability and long-term performance in Deep Q-Network based agents?
</li>

<li>
What role does environment modeling play in shaping learning efficiency and robustness in constrained decision systems?
</li>

<li>
How can reinforcement learning be formulated for distributed optimization problems 
(e.g., energy-aware resource allocation) with reproducible evaluation protocols?
</li>

<li>
Which stability mechanisms (replay buffers, target networks, masking strategies) 
most effectively reduce training variance in small-scale strategic environments?
</li>
</ul>
</div>
</div>
    </section>
    <div class="section" id="publications">
<h2>Publications & Preprints</h2>
<div class="pub-item">
    <div class="pub-title">
        Energy-Efficient Clustering Protocol for Wireless Sensor Networks
    </div>
    <div class="pub-meta">
        Conference Paper (in Persian), 2018
    </div>
    <p style="color:#aaa; font-size:14px;">
        This paper proposes an energy-aware clustering protocol 
        to extend network lifetime in wireless sensor networks 
        through optimized cluster-head selection mechanisms.
    </p>
    <div class="pub-links">
        <a href="assets/Arianfar_2018_WSN.pdf" target="_blank">PDF</a>
    </div>
</div>

<div class="pub-item">
    <div class="pub-title">
        Reinforcement Learning for Strategic Decision Systems
    </div>
  <p style="color:#aaa; font-size:14px;">
    This research transforms the Business Chessboard Strategy (BCS) into an AI-executable framework using Hierarchical Reinforcement Learning.
By modeling strategic decisions as a Hierarchical Markov Decision Process (H-MDP), the project enables RL agents to simulate, evaluate, and optimize long-term strategies under uncertainty.
A custom simulation environment (BCS-Simulator) is developed to train and analyze intelligent agents, combining deep RL methods with explainable AI tools.
The goal is to bridge human strategic theory and computational decision optimization.
    </p>
    <div class="pub-meta">
        Research Proposal
    </div>
    <div class="pub-links">
        <a href="assets/PhD_Research_Proposal.pdf" target="_blank">PDF</a>
    </div>
</div>

</div>

    <section class="section" id="projects">
      <h2>Research Projects</h2>

      <div class="project">
        <div class="project-title">
          <strong>MiniChess-RL: Deep Q-Network Agent in a Custom 4×4 Chess Environment</strong>
          <span class="links">
            <a href="https://github.com/negarinarianfar/mini-chess-rl" target="_blank">Code</a>
          </span>
        </div>
        <p class="muted">
          Built a custom 4×4 mini-chess environment and trained a DQN agent end-to-end using Python + PyTorch.
          The project demonstrates environment modeling, reward shaping, illegal move masking, training loops, and evaluation.
        </p>
            <a class="btn" href="/projects/minichess.html">View Details</a>
          
      <div class="project">
        <div class="project-title">
          <strong>Working Paper: RL Formulation of Energy-Aware Optimization (in progress)</strong>
          <span class="muted">— details coming soon</span>
        </div>
        <p class="muted">
          Translating an earlier energy optimization / clustering idea into an RL problem definition (state/action/reward),
          and planning reproducible experiments and baselines.
        </p>
        <div class="tags">
          <span class="tag">MDP Formulation</span>
          <span class="tag">Baselines</span>
          <span class="tag">Experiment Design</span>
        </div>
      </div>
    </section>
    <div class="section" id="books">
<h2>Books</h2>

<div class="books-container">

<!-- RL Book -->
<div class="book-item">
    <img src="assets/rlbook.png" alt="Learning Reinforcement Learning Through Projects: From Zero to your First Deep Q-Network">
    
    <div class="book-content">
        <h3>Learning Reinforcement Learning Through Projects: From Zero to your First Deep Q-Network </h3>
        <p>
        A practical and intuitive introduction to reinforcement learning,
        guiding readers from bandit problems to Deep Q-Networks (DQN).
        The book emphasizes environment design, reward modeling,
        instability analysis, and hands-on implementation.
        </p>
        
        <a href="https://www.amazon.com/Learning-Reinforcement-Through-Projects-Q-Network/dp/B0GPGP8X8Z/ref=sr_1_1?crid=2GNKNR40BLLBW&dib=eyJ2IjoiMSJ9.Bzqmf4jaPO1OM_5KWgHtktPxSMQIuHB795fO9CO00CA.RIeEburETbevL1zJuSMeNQVz5081vXzj59dRB7Un4ds&dib_tag=se&keywords=negar+arianfar&qid=1772054116&s=books&sprefix=%2Cstripbooks%2C187&sr=1-1" target="_blank" class="amazon-btn">
        View on Amazon
        </a>
    </div>
</div>

<!-- Business Book -->
<div class="book-item">
    <img src="assets/chessbook.png" alt="Chessboard of Business">
    
    <div class="book-content">
        <h3>Chessboard of Business</h3>
        <p>
        A strategic guide to building successful businesses through
        structured decision-making, foresight, and chess-inspired thinking.
        Focused on practical frameworks for sustainable growth.
        </p>
        
        <a href="https://www.amazon.com/Chessboard-Business-Negar-Arianfar/dp/B0FVVR5H9P/ref=sr_1_6?crid=30GQIEPDHUTQN&dib=eyJ2IjoiMSJ9.KREht6HSbQovaIJXJG4SRw_F-z8rxR78Ba0kH6JLxpnBH4sWAHQz1ig-xRlHZlJmTXpUi-z9-MutyM7bxSljggNU1ivA7ims9Ixvlm6K-vE3V4Yp1gC1-GoTgT0t9hNF8y5jmTkqxBAXROTTxfdTj3g642BUPHVa8SrENOsjLOs6NT3POkS7gtqIiBdFxThDgrUPLKfagtCGnuxsy055_9B8XDdiTYoDOKEkDQVnbC8.9XYZJAT5aUOU9lR9SBXjPEG4rx-KxJS1LA4wPuHkgok&dib_tag=se&keywords=chessboard+of+Business&qid=1771977635&sprefix=chessboard+of+business+%2Caps%2C207&sr=8-6" target="_blank" class="amazon-btn">
        View on Amazon
        </a>
    </div>
</div>

</div>
</div>

    <section class="section" id="cv">
      <h2>CV</h2>
        <a class="btn primary" href="assets/Arianfar_CV.pdf" target="_blank">
        Download Academic CV
        </a>
    </section>

    <section class="section" id="contact">
      <h2>Contact</h2>
      <p class="muted">
        Email: <a href="mailto:negarinarianfar@gmail.com" style="color:var(--accent);text-decoration:none;">negarinarianfar@gmail.com</a><br/>
        GitHub: <a href="https://github.com/negarinarianfar" target="_blank" style="color:var(--accent);text-decoration:none;">github.com/negarinarianfar</a><br/>
        Linkedin: <a href="https://linkedin.com/in/negar-arianfar" target="_blank" style="color:var(--accent);text-decoration:none;">linkedin.com/in/negar-arianfar</a>
      </p>
    </section>

    <footer>© 2026 Negar Arianfar</footer>

  </div>
</body>
</html>
