<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Negarin Arianfar</title>

<style>
  :root{
    --bg:#0b1220;
    --panel:#0f172a;
    --text:#e5e7eb;
    --muted:#9ca3af;
    --line:#1f2a44;
    --accent:#38bdf8;
    --accent2:#a78bfa;
  }
  *{box-sizing:border-box}
  body{
    margin:0;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif;
    background: radial-gradient(1200px 700px at 20% 10%, rgba(56,189,248,0.15), transparent 60%),
                radial-gradient(900px 600px at 80% 30%, rgba(167,139,250,0.12), transparent 60%),
                var(--bg);
    color:var(--text);
    line-height:1.6;
  }
  .container{width:88%; max-width:1050px; margin:0 auto;}
  nav{
    display:flex; justify-content:flex-end; gap:18px;
    padding:22px 0;
    position:sticky; top:0;
    background: rgba(11,18,32,0.75);
    backdrop-filter: blur(10px);
    border-bottom:1px solid rgba(31,42,68,0.6);
    z-index:10;
  }
  nav a{
    color:var(--muted); text-decoration:none; font-size:14px;
    padding:8px 10px; border-radius:10px;
  }
  nav a:hover{color:var(--accent); background:rgba(56,189,248,0.08);}
  .hero{padding:70px 0 30px;}
  .kicker{
    display:inline-flex; gap:10px; align-items:center;
    font-size:13px; color:var(--muted);
    border:1px solid rgba(31,42,68,0.8);
    padding:8px 12px; border-radius:999px;
    background: rgba(15,23,42,0.65);
  }
  .dot{width:8px;height:8px;border-radius:50%;background:var(--accent); box-shadow:0 0 18px rgba(56,189,248,0.6);}
  h1{font-size:46px; margin:18px 0 10px; letter-spacing:-0.5px;}
  .subtitle{font-size:18px; color:var(--muted); max-width:780px;}
  .cta{display:flex; gap:12px; flex-wrap:wrap; margin-top:22px;}
  .btn{
    display:inline-flex; align-items:center; gap:10px;
    padding:10px 14px; border-radius:14px;
    text-decoration:none; font-size:14px;
    border:1px solid rgba(31,42,68,0.9);
    background: rgba(15,23,42,0.75);
    color:var(--text);
  }
  .btn:hover{border-color:rgba(56,189,248,0.6); box-shadow:0 0 0 3px rgba(56,189,248,0.08);}
  .btn.primary{
    background: linear-gradient(135deg, rgba(56,189,248,0.22), rgba(167,139,250,0.18));
    border-color: rgba(56,189,248,0.35);
  }
    

/* Make ONLY the main hero wrapper relative */
/* اسم کلاس رو اگر فرق داشت عوض کن */
.hero, .main-hero, .landing {
  position: relative;
  min-height: 520px;   /* این خط مهمه */
}

/* Avatar placement */
.profile-pic{
  position: absolute;

  right: 1%;      /* قبلاً 10% بود → نزدیک‌تر به لبه */
  top: 90px;     /* اگر لازم شد 140–170 تنظیم کن */

  width: 230px;   /* بزرگ‌تر */
  height: 230px;

  border-radius: 50%;
  object-fit: cover;

  border: 2px solid rgba(255,255,255,0.12);
  box-shadow: 
      0 0 50px rgba(0,140,255,0.15),
      0 25px 50px rgba(0,0,0,0.5);

  z-index: 2;
}

/* Hide on small screens */
@media (max-width: 1000px){
  .profile-pic{
    display: none;
  }
}
box-shadow: 0 0 40px rgba(0,140,255,0.15),
            0 20px 40px rgba(0,0,0,0.45);
  

  .grid{display:grid; grid-template-columns: 1fr; gap:18px; margin-top:28px;}
  @media(min-width:900px){
    .grid{grid-template-columns: 1.2fr 0.8fr;}
  }

  .card{
    border:1px solid rgba(31,42,68,0.9);
    background: rgba(15,23,42,0.65);
    border-radius:20px;
    padding:18px 18px;
  }
  .card h3{margin:0 0 10px; font-size:16px; color:var(--accent);}
  .section{padding:34px 0; border-top:1px solid rgba(31,42,68,0.7);}
  .section h2{margin:0 0 14px; color:var(--accent); font-size:18px;}
  .muted{color:var(--muted)}
  .tags{display:flex; flex-wrap:wrap; gap:8px; margin-top:10px;}
  .tag{
    font-size:12px; color:var(--muted);
    padding:6px 10px; border-radius:999px;
    border:1px solid rgba(31,42,68,0.9);
    background: rgba(11,18,32,0.35);
  }
  .project{
    padding:16px; border-radius:18px;
    border:1px solid rgba(31,42,68,0.9);
    background: rgba(11,18,32,0.35);
    margin-top:12px;
  }
  .project-title{display:flex; justify-content:space-between; gap:10px; flex-wrap:wrap;}
  .project-title strong{font-size:15px;}
  .links a{color:var(--accent); text-decoration:none; font-size:13px; margin-right:12px;}
  .links a:hover{text-decoration:underline;}
  ul{margin:10px 0 0 18px; color:var(--muted)}
  footer{padding:32px 0; text-align:center; color:var(--muted); font-size:13px;}
</style>
  <style>
.books-container {
    display: flex;
    flex-direction: column;
    gap: 40px;
}

.book-item {
    display: flex;
    gap: 30px;
    align-items: center;
    background-color: #1a1a1a;
    padding: 20px;
    border-radius: 12px;
}

.book-item img {
    width: 160px;
    border-radius: 10px;
}

.book-content {
    flex: 1;
}

.book-content h3 {
    margin: 0 0 10px 0;
    color: #ffffff;
}

.book-content p {
    color: #cccccc;
    line-height: 1.6;
}

.amazon-btn {
    display: inline-block;
    margin-top: 15px;
    padding: 8px 16px;
    background-color: #00bfff;
    color: #000;
    text-decoration: none;
    border-radius: 6px;
    font-weight: bold;
    transition: 0.3s;
}

.amazon-btn:hover {
    background-color: #009acd;
}
</style>
  <style>
.research-questions {
    background-color: #141414;
    padding: 25px;
    border-radius: 12px;
    margin-top: 20px;
}

.research-questions ul {
    padding-left: 20px;
}

.research-questions li {
    margin-bottom: 12px;
    color: #cccccc;
    line-height: 1.6;
}
</style>
  <style>
.pub-item {
    background-color: #141414;
    padding: 18px;
    border-radius: 10px;
    margin-bottom: 15px;
}

.pub-title {
    color: #ffffff;
    font-weight: bold;
}

.pub-meta {
    color: #aaaaaa;
    font-size: 14px;
    margin: 5px 0;
}

.pub-links a {
    color: #00bfff;
    text-decoration: none;
    margin-right: 15px;
    font-weight: bold;
}

.pub-links a:hover {
    text-decoration: underline;
}
</style>

  <style>
.results-box {
    background-color: #101820;
    padding: 15px;
    border-radius: 10px;
    margin-top: 15px;
    font-size: 14px;
    color: #cccccc;
}

.results-box strong {
    color: #ffffff;
}

.results-box img {
    width: 100%;
    max-width: 500px;
    margin-top: 15px;
    border-radius: 8px;
}
</style>


</head>

<body>
  <div class="container">

    <nav>
      <a href="#about">About</a>
      <a href="#vision">Research Vision</a>
      <a href="#projects">Projects</a>
      <a href="#books">Books</a>
      <a href="#cv">CV</a>
      <a href="#contact">Contact</a>
    </nav>

    <header class="hero">
      <span class="kicker"><span class="dot"></span> Prospective PhD Applicant • Reinforcement Learning</span>
      <h1>Negar Arianfar</h1>
      <img class="profile-pic" src="/assets/img/Profile.jpg" alt="Negar Arianfar" />
      <p class="subtitle">
        Applied Reinforcement Learning • Decision Systems • From Theory to Implementation
      </p>
      <p class="subtitle">
        I work on applied reinforcement learning and sequential decision-making —
        bridging theory to reproducible implementations (PyTorch, custom environments, evaluation).
      </p>

      <div class="cta">
        <a class="btn primary" href="https://github.com/negarinarianfar" target="_blank">GitHub</a>
        <a class="btn" href="#projects">View Research Projects</a>
        <a class="btn" href="mailto:negarinarianfar@gmail.com">Email</a>
      </div>

      <div class="grid">
        <div class="card">
          <h3>Research Interests</h3>
          <p class="muted">
            Reinforcement Learning • Decision-Making Systems • Reward Design • Safe & Robust Learning • Multi-Agent / Distributed Optimization
          </p>
          <div class="tags">
            <span class="tag">RL</span>
            <span class="tag">DQN</span>
            <span class="tag">MDP Modeling</span>
            <span class="tag">Reward Shaping</span>
            <span class="tag">Evaluation</span>
          </div>
        </div>

        <div class="card">
          <h3>Currently Working On</h3>
          <p class="muted">
            Rewriting my earlier work in energy-aware optimization into an RL formulation and building an implementable research prototype.
          </p>
          <div class="tags">
            <span class="tag">Working Paper</span>
            <span class="tag">RL for Optimization</span>
            <span class="tag">From Theory → Implementation</span>
          </div>
        </div>
      </div>
    </header>

    <section class="section" id="about">
      <h2>About</h2>
      <p class="muted">
        I am an applied ML researcher focused on building reinforcement learning systems that can be tested,
        measured, and extended. I enjoy designing environments, implementing agents, and running structured evaluations
        to answer research questions with reproducible code.
      </p>
      <p class="muted">
        M.Sc. in Business Management
  International Marketing & Sales  
  Hochschule der Wirtschaft für Management (HDWM), Germany (2023–2025)<br>
M.Sc. in Software Engineering
  University of Najaf Abad Azad, Iran (2014–2018)<br>
B.Sc. in Hardware Engineering
  University of Najaf Abad Azad, Iran (2008–2014)
      </p>
    </section>

    <section class="section" id="vision">
  <h2>Research Vision</h2>
  <p class="muted">
    My research focuses on designing reinforcement learning systems that move beyond theoretical formulation toward robust, reproducible implementations.
    I am particularly interested in how environment modeling, reward design, and stability mechanisms influence long-term decision performance.
  </p>
  <p class="muted">
    I aim to develop learning-based optimization frameworks for distributed and strategic decision-making problems, 
    with an emphasis on reliability, evaluation methodology, and practical scalability.
  </p>
<div class="section" id="research-questions">
<h2>Research Questions</h2>

<div class="research-questions">
<ul>
<li>
How does reward design influence stability and long-term performance in Deep Q-Network based agents?
</li>

<li>
What role does environment modeling play in shaping learning efficiency and robustness in constrained decision systems?
</li>

<li>
How can reinforcement learning be formulated for distributed optimization problems 
(e.g., energy-aware resource allocation) with reproducible evaluation protocols?
</li>

<li>
Which stability mechanisms (replay buffers, target networks, masking strategies) 
most effectively reduce training variance in small-scale strategic environments?
</li>
</ul>
</div>
</div>
    </section>
    <div class="section" id="publications">
<h2>Publications & Preprints</h2>
<div class="pub-item">
    <div class="pub-title">
        Energy-Efficient Clustering Protocol for Wireless Sensor Networks
    </div>
    <div class="pub-meta">
        Conference Paper (in Persian), 2018
    </div>
    <p style="color:#aaa; font-size:14px;">
        This paper proposes an energy-aware clustering protocol 
        to extend network lifetime in wireless sensor networks 
        through optimized cluster-head selection mechanisms.
    </p>
    <div class="pub-links">
        <a href="assets/Arianfar_2018_WSN.pdf" target="_blank">PDF</a>
    </div>
</div>

<div class="pub-item">
    <div class="pub-title">
        Reinforcement Learning for Strategic Decision Systems
    </div>
  <p style="color:#aaa; font-size:14px;">
    This research transforms the Business Chessboard Strategy (BCS) into an AI-executable framework using Hierarchical Reinforcement Learning.
By modeling strategic decisions as a Hierarchical Markov Decision Process (H-MDP), the project enables RL agents to simulate, evaluate, and optimize long-term strategies under uncertainty.
A custom simulation environment (BCS-Simulator) is developed to train and analyze intelligent agents, combining deep RL methods with explainable AI tools.
The goal is to bridge human strategic theory and computational decision optimization.
    </p>
    <div class="pub-meta">
        Research Proposal
    </div>
    <div class="pub-links">
        <a href="assets/PhD_Research_Proposal.pdf" target="_blank">PDF</a>
    </div>
</div>

</div>

    <section class="section" id="projects">
      <h2>Research Projects</h2>

      <div class="project">
        <div class="project-title">
          <strong>MiniChess-RL: Deep Q-Network Agent in a Custom 4×4 Chess Environment</strong>
          <span class="links">
            <a href="https://github.com/negarinarianfar/mini-chess-rl" target="_blank">Code</a>
          </span>
        </div>
        <p class="muted">
          Built a custom 4×4 mini-chess environment and trained a DQN agent end-to-end using Python + PyTorch.
          The project demonstrates environment modeling, reward shaping, illegal move masking, training loops, and evaluation.
        </p>
        <ul>
          <li>Custom Gym-style environment with full MDP formalization</li>
          <li>State encoding: 4-channel tensor (WK, WR, BK, turn); action space: 256 (from×to)</li>
          <li>DQN with replay buffer, target network, epsilon-greedy exploration</li>
          <li>Evaluation pipeline and reward-curve visualization</li>
        </ul>
        <div class="results-box">
<strong>Experimental Results</strong><br><br>

Average reward (100 evaluation episodes, greedy policy): -0.588 <br>
Win rate vs random opponent: 19% <br>
Training episodes: 2000 <br>
State encoding: 4×4×4 tensor<br><br>

<strong>Training Curve (Moving Average, window=50)</strong><br>
<img src="assets/minichess_reward_curve.png" alt="MiniChess RL Reward Curve">
<br><br>

<strong>Run Instructions:</strong><br>
Train: <code>python3 training/train.py</code><br>
Evaluate: <code>python3 training/evaluate.py</code>
</div>
        <div class="tags">
          <span class="tag">PyTorch</span>
          <span class="tag">DQN</span>
          <span class="tag">Environment Design</span>
          <span class="tag">Illegal Action Masking</span>
          <span class="tag">Evaluation</span>
        </div>
      </div>

      <div class="project">
        <div class="project-title">
          <strong>Working Paper: RL Formulation of Energy-Aware Optimization (in progress)</strong>
          <span class="muted">— details coming soon</span>
        </div>
        <p class="muted">
          Translating an earlier energy optimization / clustering idea into an RL problem definition (state/action/reward),
          and planning reproducible experiments and baselines.
        </p>
        <div class="tags">
          <span class="tag">MDP Formulation</span>
          <span class="tag">Baselines</span>
          <span class="tag">Experiment Design</span>
        </div>
      </div>
    </section>
    <div class="section" id="books">
<h2>Books</h2>

<div class="books-container">

<!-- RL Book -->
<div class="book-item">
    <img src="assets/rlbook.png" alt="Learning Reinforcement Learning Through Projects: From Zero to your First Deep Q-Network">
    
    <div class="book-content">
        <h3>Learning Reinforcement Learning Through Projects: From Zero to your First Deep Q-Network </h3>
        <p>
        A practical and intuitive introduction to reinforcement learning,
        guiding readers from bandit problems to Deep Q-Networks (DQN).
        The book emphasizes environment design, reward modeling,
        instability analysis, and hands-on implementation.
        </p>
        
        <a href="https://www.amazon.com/Learning-Reinforcement-Through-Projects-Q-Network/dp/B0GPGP8X8Z/ref=sr_1_1?crid=17K1TT2X3M7I3&dib=eyJ2IjoiMSJ9.L4bzY_O1hfxRg4WIdU3yngHKNfbIJ-VLNBVjo3N7k4n2QyPIXdKH0TkYqgqM76WjJfSGjRpit20soxLPachegw.vHMQScvnkGGYyTqhXN7htsZ374-_oT7lW80lnHTzvU8&dib_tag=se&keywords=learning+reinforcement+learning+projects+negar+arianfar&qid=1771977543&sprefix=learning+reinforcement+learning+projects+negar+arianfar%2Caps%2C174&sr=8-1" target="_blank" class="amazon-btn">
        View on Amazon
        </a>
    </div>
</div>

<!-- Business Book -->
<div class="book-item">
    <img src="assets/chessbook.png" alt="Chessboard of Business">
    
    <div class="book-content">
        <h3>Chessboard of Business</h3>
        <p>
        A strategic guide to building successful businesses through
        structured decision-making, foresight, and chess-inspired thinking.
        Focused on practical frameworks for sustainable growth.
        </p>
        
        <a href="https://www.amazon.com/Chessboard-Business-Negar-Arianfar/dp/B0FVVR5H9P/ref=sr_1_6?crid=30GQIEPDHUTQN&dib=eyJ2IjoiMSJ9.KREht6HSbQovaIJXJG4SRw_F-z8rxR78Ba0kH6JLxpnBH4sWAHQz1ig-xRlHZlJmTXpUi-z9-MutyM7bxSljggNU1ivA7ims9Ixvlm6K-vE3V4Yp1gC1-GoTgT0t9hNF8y5jmTkqxBAXROTTxfdTj3g642BUPHVa8SrENOsjLOs6NT3POkS7gtqIiBdFxThDgrUPLKfagtCGnuxsy055_9B8XDdiTYoDOKEkDQVnbC8.9XYZJAT5aUOU9lR9SBXjPEG4rx-KxJS1LA4wPuHkgok&dib_tag=se&keywords=chessboard+of+Business&qid=1771977635&sprefix=chessboard+of+business+%2Caps%2C207&sr=8-6" target="_blank" class="amazon-btn">
        View on Amazon
        </a>
    </div>
</div>

</div>
</div>

    <section class="section" id="cv">
      <h2>CV</h2>
        <a class="btn primary" href="assets/Arianfar_CV.pdf" target="_blank">
        Download Academic CV
        </a>
    </section>

    <section class="section" id="contact">
      <h2>Contact</h2>
      <p class="muted">
        Email: <a href="mailto:negarinarianfar@gmail.com" style="color:var(--accent);text-decoration:none;">negarinarianfar@gmail.com</a><br/>
        GitHub: <a href="https://github.com/negarinarianfar" target="_blank" style="color:var(--accent);text-decoration:none;">github.com/negarinarianfar</a><br/>
        Linkedin: <a href="https://linkedin.com/in/negar-arianfar" target="_blank" style="color:var(--accent);text-decoration:none;">linkedin.com/in/negar-arianfar</a>
      </p>
    </section>

    <footer>© 2026 Negar Arianfar</footer>

  </div>
</body>
</html>
