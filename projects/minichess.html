<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MiniChess-RL | Negar Arianfar</title>

  <!-- اگر سایتت style.css در روت هست همین درسته -->
  <link rel="stylesheet" href="/style.css" />

  <style>
    .page {
      max-width: 980px;
      margin: 90px auto;
      padding: 0 20px 60px;
    }

    .breadcrumbs {
      opacity: 0.75;
      font-size: 14px;
      margin-bottom: 14px;
    }
    .breadcrumbs a { text-decoration: none; }

    .header {
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 18px;
      flex-wrap: wrap;
      margin-bottom: 18px;
    }

    .title h1 {
      margin: 0 0 8px 0;
      font-size: 2rem;
      letter-spacing: 0.2px;
    }
    .subtitle {
      opacity: 0.8;
      max-width: 62ch;
      line-height: 1.55;
      margin: 0;
    }

    .actions {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      margin-top: 6px;
    }

    .btn {
      display: inline-block;
      padding: 9px 14px;
      border-radius: 12px;
      border: 1px solid rgba(255,255,255,0.18);
      background: rgba(255,255,255,0.03);
      text-decoration: none;
      transition: 0.25s ease;
      font-size: 14px;
      opacity: 0.95;
    }
    .btn:hover {
      transform: translateY(-2px);
      border-color: rgba(0,140,255,0.55);
    }

    .pill-row { margin: 14px 0 8px; display:flex; gap:8px; flex-wrap: wrap; }
    .pill {
      font-size: 12.5px;
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.14);
      background: rgba(255,255,255,0.02);
      opacity: 0.9;
    }

    .card {
      margin-top: 18px;
      border: 1px solid rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.03);
      border-radius: 18px;
      padding: 18px;
    }

    .card h2 {
      margin: 0 0 10px 0;
      font-size: 1.1rem;
    }
    .card p, .card li {
      opacity: 0.88;
      line-height: 1.65;
    }

    .grid-2 {
      display: grid;
      gap: 14px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
    }
    @media (max-width: 860px) {
      .grid-2 { grid-template-columns: 1fr; }
    }

    .kpi {
      display: grid;
      gap: 12px;
      grid-template-columns: repeat(3, minmax(0, 1fr));
      margin-top: 10px;
    }
    @media (max-width: 860px) {
      .kpi { grid-template-columns: 1fr; }
    }

    .kpi-box {
      border: 1px solid rgba(255,255,255,0.10);
      border-radius: 16px;
      padding: 12px 14px;
      background: rgba(0,0,0,0.12);
    }
    .kpi-label { font-size: 13px; opacity: 0.75; }
    .kpi-value { font-size: 20px; margin-top: 6px; font-weight: 600; }
    .kpi-note  { font-size: 12.5px; opacity: 0.7; margin-top: 2px; }

    code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.95em;
      opacity: 0.95;
    }

    .figure {
      margin-top: 10px;
      border: 1px solid rgba(255,255,255,0.10);
      border-radius: 16px;
      overflow: hidden;
      background: rgba(0,0,0,0.12);
    }
    .figure img {
      width: 100%;
      height: auto;
      display: block;
    }
    .figure figcaption {
      padding: 10px 12px;
      font-size: 13px;
      opacity: 0.75;
    }

    .hr {
      height: 1px;
      background: rgba(255,255,255,0.10);
      margin: 18px 0;
    }
  </style>
</head>

<body>
  <main class="page">

    <div class="breadcrumbs">
      ← <a href="/projects/">Projects</a>
    </div>

    <div class="header">
      <div class="title">
        <h1>MiniChess-RL</h1>
        <p class="subtitle">
          A reproducible reinforcement learning pipeline for a custom 4×4 mini-chess environment,
          focused on environment design, reward shaping, and structured evaluation.
        </p>

        <div class="pill-row">
          <span class="pill">Reinforcement Learning</span>
          <span class="pill">DQN</span>
          <span class="pill">Environment Design</span>
          <span class="pill">Reward Shaping</span>
          <span class="pill">Evaluation</span>
        </div>
      </div>

      <div class="actions">
        <a class="btn" href="https://github.com/negarinarianfar/mini-chess-rl" target="_blank" rel="noreferrer">
          GitHub Repo
        </a>
        <!-- اگر PDF گزارش/تکنیکال ریپورت رو بعداً گذاشتی -->
        <!-- <a class="btn" href="/assets/pdf/minichess_report.pdf" target="_blank" rel="noreferrer">PDF Report</a> -->
      </div>
    </div>

    <section class="card">
      <h2>Research Question</h2>
      <p>
        How do environment design choices (state/action formalization, illegal-move handling)
        and reward shaping affect learning stability and measurable performance in a compact
        chess-like decision environment with a large discrete action space?
      </p>
    </section>

    <section class="card">
      <h2>System Overview</h2>
      <div class="grid-2">
        <div>
          <ul>
            <li><b>Environment:</b> custom 4×4 mini-chess</li>
            <li><b>State:</b> tensor-based representation</li>
            <li><b>Action space:</b> up to 256 discrete actions (including illegal moves handling)</li>
            <li><b>Opponent:</b> baseline opponent for evaluation (e.g., random)</li>
          </ul>
        </div>
        <div>
          <ul>
            <li><b>Agent:</b> Deep Q-Network (PyTorch)</li>
            <li><b>Core components:</b> replay buffer, target network, ε-greedy exploration</li>
            <li><b>Goal:</b> reproducible training + structured evaluation protocol</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="card">
      <h2>Method Details</h2>
      <ul>
        <li><b>Learning algorithm:</b> DQN with target network stabilization</li>
        <li><b>Exploration:</b> epsilon-greedy with decay schedule</li>
        <li><b>Training loop:</b> experience collection → replay sampling → Q-update → periodic target sync</li>
        <li><b>Reward design:</b> terminal rewards (win/loss) + shaping (captures / illegal move penalty / etc.)</li>
      </ul>
    </section>

    <section class="card">
      <h2>Results (measurable metrics)</h2>

      <!-- این 3 تا KPI رو وقتی عدد داری پر کن -->
      <div class="kpi">
        <div class="kpi-box">
          <div class="kpi-label">Win rate vs baseline</div>
          <div class="kpi-value">TBD%</div>
          <div class="kpi-note">evaluated over N games</div>
        </div>

        <div class="kpi-box">
          <div class="kpi-label">Average reward</div>
          <div class="kpi-value">TBD</div>
          <div class="kpi-note">mean ± std (N episodes)</div>
        </div>

        <div class="kpi-box">
          <div class="kpi-label">Training stability</div>
          <div class="kpi-value">TBD</div>
          <div class="kpi-note">variance / curve smoothness</div>
        </div>
      </div>

      <div class="hr"></div>

      <p>
        Optional figure: add a training curve image at
        <code>/assets/img/projects/reward_curve.png</code> and uncomment the block below.
      </p>

      <!--
      <figure class="figure">
        <img src="/assets/img/projects/reward_curve.png" alt="Training curve: reward over episodes">
        <figcaption>Training curve (reward over episodes).</figcaption>
      </figure>
      -->
    </section>

    <section class="card">
      <h2>Reproducibility</h2>
      <ul>
        <li><b>Re-run:</b> keep dependencies pinned (requirements / environment file)</li>
        <li><b>Seeds:</b> run multiple seeds to estimate variance</li>
        <li><b>Evaluation protocol:</b> fixed number of games vs baseline at set checkpoints</li>
      </ul>

      <p class="muted">
        Suggested command format (edit to match your repo):
        <br/>
        <code>python train.py --episodes 1000 --seed 0</code>
      </p>
    </section>

    <section class="card">
      <h2>Limitations & Next Steps</h2>
      <ul>
        <li>Run ablations: compare reward shaping variants and illegal-move handling strategies.</li>
        <li>Add stronger baselines (heuristic agent) and more rigorous evaluation (multiple seeds).</li>
        <li>Extend toward self-play / multi-agent setups to study learning dynamics.</li>
      </ul>
    </section>

    <p style="opacity:0.8; margin-top:18px;">
      ← Back to <a href="/projects/">Projects</a>
    </p>

  </main>
</body>
</html>
